{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object_detection (practice).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "1MRyLagVRoz8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z-XmRq4ZR0PA",
        "colab_type": "code",
        "outputId": "d8a2ae51-f1ee-4165-aafe-945af270b956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "num_imgs = 50000\n",
        "\n",
        "img_size = 16\n",
        "min_rect_size = 3\n",
        "max_rect_size = 8\n",
        "num_objects = 2\n",
        "\n",
        "bboxes = np.zeros((num_imgs, num_objects, 4))\n",
        "imgs = np.zeros((num_imgs, img_size, img_size))\n",
        "shapes = np.zeros((num_imgs, num_objects, 1))\n",
        "\n",
        "for i_img in range(num_imgs):\n",
        "    for i_object in range(num_objects):\n",
        "        if np.random.choice([True, False]):\n",
        "            width, height = np.random.randint(min_rect_size, max_rect_size, size=2)\n",
        "            x = np.random.randint(0, img_size - width)\n",
        "            y = np.random.randint(0, img_size - height)\n",
        "            imgs[i_img, x:x+width, y:y+height] = 1.\n",
        "            bboxes[i_img, i_object] = [x, y, width, height]\n",
        "            shapes[i_img, i_object] = [0]\n",
        "        else:\n",
        "            size = np.random.randint(min_rect_size, max_rect_size)\n",
        "            x, y = np.random.randint(0, img_size - size, size=2)\n",
        "            mask = np.tril_indices(size)\n",
        "            imgs[i_img, x + mask[0], y + mask[1]] = 1.\n",
        "            bboxes[i_img, i_object] = [x, y, size, size]\n",
        "            shapes[i_img, i_object] = [1]\n",
        "        \n",
        "imgs.shape, bboxes.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 16, 16), (50000, 2, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "M8l5MogzR0L1",
        "colab_type": "code",
        "outputId": "29b7ff5f-699f-4136-83d1-e0094d149790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "i = 5000\n",
        "# TODO: Why does the array have to be transposed?\n",
        "plt.imshow(imgs[i].T, cmap='Greys', interpolation='none', origin='lower', extent=[0, img_size, 0, img_size])\n",
        "for bbox, shape in zip(bboxes[i], shapes[i]):\n",
        "    plt.gca().add_patch(matplotlib.patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], ec='r' if shape[0] == 0 else 'y', fc='none'))\n",
        "\n",
        "print(imgs[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD8CAYAAABetbkgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADiJJREFUeJzt3X2sZPVdx/H37S2VZbEVUQRKA3QL\nX62rTQUfmkpZHizQYoiytYkLpRZFw4NNSFOpNTyJrQURWyC2JBRaEmIfFmRrt1ABA1VLoo02Vsx3\n6WZpcXkWS1nYBXa5/jHnssO4c+/eM78zO3d/71eyybnnnJnzvWf2M+fMub8536mZmRkk7d5etasL\nkNQ9gy5VwKBLFTDoUgUMulQBgy5V4NU7s1JELAduA67KzGsiYg/gc8CbgGeAlZn5v92VKWkU8x7R\nI2IpcDVwV9/s3wOeyMxfAr4AHNVNeZJK2Jkj+vPAu4A/6pv368BFAJl5XQd1SSpo3qBn5lZga0T0\nzz4EOCkiLgceBc7OzKfmeBqH30ndmxq2oO3FuCkgM3MF8B3gIy2fR9IYtA36Y8A9zfQdwM+WKUdS\nF9oG/WvAic30EUCWKUdSF6bm+/ZaRBwBXEnvc/mLwEbgt4FPAgcAm4AzMvOxOZ7Gz+hS94Z+Rp83\n6IUYdKl7xS/GSVpEDLpUAYMuVcCgSxUw6FIFDLpUAYMuVcCgSxUw6FIFDLpUAYMuVcCgSxUw6FIF\nDLpUAYMuVcCgSxUw6FIFDLpUgZ0KekQsj4j1EXHuwPwTIsLbREkTrm1LJiJiT3r3c3+km9IklbIz\nR/TZlkwPD8z/Y+Ba4IXSRUkqq1VLpog4HHhLZl4YEVd0WN+CTU9NsWzIsnWZHP7K1lK7xGKoY93W\nrTA9PeaK1JWdapu8A1cBf1iykFK2ZcKGDXDooTtcvi4no9fERNexYQOsXw+HHz7+gtSJnb6ve0Rc\nDDwJ3ArcCzzRLHorcF9mHj3Hw8d2we7wqd6trR/YUREzM0xNDb319dhMeh2H0bwBGPTFZuh/qgUf\n0TNzI2w/O46IB+cJuaRdbN6gD7ZkioiVwG/O0yZZ0gTZ7Voyeeo+eh2eui9atmSSambQpQoYdKkC\nBl2qgEGXKmDQpQoYdKkCBl2qgEGXKmDQpQoYdKkCBl2qgEGXKmDQpQoYdKkCBl2qgEGXKmDQpQoY\ndKkCO3UX2IhYDtwGXJWZ10TEG4AbgD2AF4HTMvPR7sqUNIq2vdcuA65rbvN8K3B+N+VJKqFt77Wz\ngdXN9BPAvoXrklRQq95rmfksQERMA+cAl3ZV4EK93GJoyK2Kx3R763lNdB3r1o2/EHWqbe+12ZDf\nBNydmXfNt/64zDYN9L7u7et4+b7u2m2MctX9BuCBzLykVDGSutEq6BGxCnghMy8qXI+kDszbkmmw\n9xqwEdgP2AL8sFnt/sw8e46nsSXTIqrDlkyLVvtuqpn5LWBFyWokjZcj46QKGHSpAgZdqoBBlypg\n0KUKGHSpAgZdqoBBlypg0KUKGHSpAgZdqoBBlypg0KUKGHSpAgZdqoBBlypg0KUKGHSpAqO0ZLoJ\nmAYeAU7PzOe7K1PSKNq2ZLoUuDYzjwK+C3ygm/IkldC2JdMKYE0z/RXg+LJlSSqpVUsmYGnfqfrj\nwAEd1NaKLZkWxpZMdWjdkqnPrr9BeR9bMo1ehy2Zdj9tr7pvioglzfTreeVpvaQJ0zbodwKnNtOn\nAreXKUdSF+Y9dR9syRQRK4FVwI0R8fvA94DPdVmkpNGM0pLp14pXI6kTjoyTKmDQpQoYdKkCBl2q\ngEGXKmDQpQoYdKkCBl2qgEGXKmDQpQoYdKkCBl2qgEGXKmDQpQoYdKkCBl2qgEGXKmDQpQq0ut1z\nROwNfB7YB/gR4JLMvKNkYZLKaXtEfz+QmXkMsBL4ZLGKJBXXtoHDk8DPN9P7ND9PjEOHLVi3jsPG\nWcgwE17H0P2nRWuqbWugiLgdeBO9oL87M++bY/Xx9R/atg3Wrx/b5nZby5bB9PSurkILM7T9T9vP\n6KcB38/MEyPiLcD1wJEtiytrenpo3zWpVm0/o78duAMgM78NHBgRvv1LE6pt0L8L/DJARBwMbMrM\nbcWqklRU24txnwE+GxH3NM/xB+VKklRa64txCzQZzcCl3dvQi3GOjJMqYNClChh0qQIGXaqAQZcq\nYNClChh0qQIGXaqAQZcqYNClChh0qQIGXaqAQZcqYNClChh0qQIGXaqAQZcqYNClCrS9ZxwRsQr4\nMLAVuDAzv1qsKklFtTqiR8S+wEXArwInA6eULEpSWW2P6McDd2bmM8AzwFnlShq/mZltbN48+d1d\nlixZxtSUt8/XwrX9jH4IsFdErImIb0TEcQVrGrvNm9ezZcuGXV3GnLZs2bAo3ow0mdoe0aeAfYHf\nAA4G/iEiDs7MRXtb5z33PJS99hpfK6epqaF35t2hgw6CzOyoGu3u2h7RHwP+OTO3ZuZ6eqfvP1mu\nLEkltQ3614FjI+JVzYW5vZmw1smStmsV9MzcCHwZuA/4GnBeZr5UsjBJ5bT+O3pmfoZeDzZJE86R\ncVIFDLpUAYMuVcCgSxUw6FIFDLpUAYMuVcCgSxVoPWBGC/9iyqyZmUX73R8tUh7RpQoYdKkCBl2q\ngEGXKmDQpQoYdKkCBl2qgEGXKmDQpQqMFPSIWBIR6yPi/YXqkdSBUY/ofwI8VaIQSd1pHfSI+Gng\nzYDNFaUJN8qXWq4EzgXOKFTLojPKl1MW+tjnnlvXeltS226q7wO+mZmT3bBsASKCqampsfwDFvyY\niNjFe0iLWdsj+ruBN0bEycBBwPMR8d+ZeWe50iSV0iromfne2emIuBh40JBLk8u/o0sVGPkOM5l5\ncYE6JHXII7pUAYMuVcCgSxUw6FIFDLpUAYMuVcCgSxWwU0vjgAPGt63nnlvHQQct7DHjrE+7n6kx\ntQea6B5EMzPb2Lx5/a4uY15Llixjamp6V5ehyTW0R5hBl3YfQ4PuZ3SpAgZdqoBBlypg0KUKGHSp\nAgZdqoBBlypg0KUKtB4CGxGXA0c1z/HxzLylWFWSimp7X/djgOWZ+TbgROCvilYlqai2p+73Au9p\npn8ALI0IB2FLE6rtfd23Ac82P54JrG3mSZpAI31NNSJOoRf0d5YpR1IXRrkYdwLwUeDEzHy6XEmS\nSmv1NdWIeB3wDeD4zHx8Jx7i11Sl7g39mmrbI/p7gZ8AvtjX5fN9mfn9ls8nqUPeeELafXjjCalm\nBl2qgEGXKmDQpQoYdKkCBl2qgEGXKmDQpQoYdKkCBl2qgEGXKmDQpQoYdKkCBl2qgEGXKmDQpQoY\ndKkCBl2qgEGXKjDK7Z6vAn6F3v3gPpiZ/1KsKklFte29djRwWNN77UzgU0WrklRU21P344C/BcjM\n/wL2iYjXFqtKUlFtT933B77V9/MTzbwfDll/6G1oJXWv1MU4gyxNsLZBf5jeEXzWgcAjo5cjqQtt\ng/51YCVARPwC8HBmPlOsKklFtW7JFBF/DrwDeAk4JzO/XbIwSeWMq/eapF3IkXFSBQy6VIHWQ2CH\nmWtobEQcD3wM2Aaszcw/Lb39vm1dDhxF73f8eGbe0rfsQeChpg6AVZm5sYMaVgBfAv6zmfUfmXle\n3/Kx7I+IOBM4vW/WkZm5d9/yF4F/6lt+XGZuo5CIWA7cBlyVmddExBuAm4Bpen+tOT0znx94TPEh\n1kPquAHYA3gROC0zH+1bfwVzvH4F67gROAL4n2aVKzLzqwOPGWl/FA16/9DYiPgZ4LPA2/pW+RRw\nArARuCciVmfm/SVraOo4Blje1LEv8G/ALQOrnZSZm0pvewfuycyVQ5aNZX9k5vXA9fDya/RbA6s8\nnZkrSm+32d5S4Grgrr7ZlwLXZuaXIuJjwAeAv+57zHz/j0rVcRlwXWZ+MSLOAc4HPjzw0Llev1J1\nAHwkM/9uyGNG3h+lT92HDo2NiDcCT2XmQ5n5ErC2Wb8L9wLvaaZ/ACyNiOmOttXKmPdHvwuBzs6k\nduB54F30xl7MWgGsaaa/Ahw/8JguhljvqI6zgdXN9BPAviNuo20d8xl5f5Q+dZ9raOz+zc+zHgeW\nFd4+AM1p57PNj2fSOy0ePBX9dEQcAvwjvXfTrv788OaIWAP8OHBJZv59M39s+2NWRPwi8FD/6Wlj\nz4i4GTgYWJ2Zf1lqm5m5FdgaEf2zl/adqj8OHDDwsIUOsW5VR2Y+C9AcBM6hd6YxaNjrV6yOxrkR\ncT69/XFuZj7Zt2zk/dH1xbi5hsZ2Pmw2Ik6hF/RzBxZdSO80bQWwHDi1oxIeAC4BTgHOAK6PiNcM\nWXccw4h/F7hxB/M/BJwFvBNYFRFHjqGWWTvze3e2b5qQ3wTcnZmDp9MLef1GcRNwQWYeC/w7cPE8\n6y94f5Q+os81NHZw2etZ2OnLgkTECcBHgRMz8+n+ZZn5+b711gI/B3y5dA3NBb4vND+uj4hH6f3e\nGxjz/misAP7fxaTM/PTsdETcRW9//GuHdWyKiCWZuZkd/97jHGJ9A/BAZl4yuGCe16+YgTeYNfRd\nr2iMvD9KH9GHDo3NzAeB10bEIRHxauDkZv3iIuJ1wBXAyZn51OCyiLij7535aOA7HdWxKiI+1Ezv\nD/wUvQtvY90fzfYPBDZl5gsD8yMibo6IqaaOt7P9KnNX7mT7WdSpwO0Dy8cyxDoiVgEvZOZFw5YP\ne/0K17G6uWYDvTfjwf+PI++P4iPjBofGAm+ld1X31oh4B/CJZtXVmfkXRTe+vYaz6J3+rOubfTe9\nP4/cGhEfpHcqtpneFfnzuviMHhE/CtwM/BjwGnqngfsx5v3R1HIEcFlmntT8fAG9K8rfjIhPAMfS\ne83WZOafFd7ulcAh9P6EtRFYRe8jxJ7A94DfycwXI+JvmunNpYdYD6ljP2AL2z/r3p+ZZ8/WQe+M\n9xWvX2au7aCOq4ELgOeATfT2weMl94dDYKUKODJOqoBBlypg0KUKGHSpAgZdqoBBlypg0KUK/B8Z\nE5YEiKbzagAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc004b332e8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "SJorNoKER0Iw",
        "colab_type": "code",
        "outputId": "81ba33b2-1e40-40a0-fa50-eb0b41a66775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X = (imgs.reshape(num_imgs, -1) - np.mean(imgs)) / np.std(imgs)\n",
        "X.shape, np.mean(X), np.std(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 256), -5.379585665821196e-17, 1.0000000000000004)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "t9ReA9GeR0FS",
        "colab_type": "code",
        "outputId": "ab8b25cb-3973-47fe-9089-a58ca723523e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1103
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(X[5000].reshape(16,16).T, cmap='Greys', interpolation='none', origin='lower', extent=[0, img_size, 0, img_size])\n",
        "print(X[5000].reshape(16,16))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467 ]\n",
            " [-0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467 ]\n",
            " [-0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467   2.38068767  2.38068767  2.38068767  2.38068767\n",
            "   2.38068767  2.38068767 -0.4200467  -0.4200467 ]\n",
            " [-0.4200467  -0.4200467  -0.4200467   2.38068767 -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467   2.38068767  2.38068767  2.38068767  2.38068767\n",
            "   2.38068767  2.38068767 -0.4200467  -0.4200467 ]\n",
            " [-0.4200467  -0.4200467  -0.4200467   2.38068767  2.38068767 -0.4200467\n",
            "  -0.4200467  -0.4200467   2.38068767  2.38068767  2.38068767  2.38068767\n",
            "   2.38068767  2.38068767 -0.4200467  -0.4200467 ]\n",
            " [-0.4200467  -0.4200467  -0.4200467   2.38068767  2.38068767  2.38068767\n",
            "  -0.4200467  -0.4200467   2.38068767  2.38068767  2.38068767  2.38068767\n",
            "   2.38068767  2.38068767 -0.4200467  -0.4200467 ]\n",
            " [-0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467   2.38068767  2.38068767  2.38068767  2.38068767\n",
            "   2.38068767  2.38068767 -0.4200467  -0.4200467 ]\n",
            " [-0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467   2.38068767  2.38068767  2.38068767  2.38068767\n",
            "   2.38068767  2.38068767 -0.4200467  -0.4200467 ]\n",
            " [-0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467 ]\n",
            " [-0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467 ]\n",
            " [-0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467 ]\n",
            " [-0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467 ]\n",
            " [-0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467 ]\n",
            " [-0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467 ]\n",
            " [-0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467 ]\n",
            " [-0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467  -0.4200467\n",
            "  -0.4200467  -0.4200467  -0.4200467  -0.4200467 ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD8CAYAAABetbkgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBl0q4P8AzsHeprdriAAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc0075adef0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "hvga4RBJR0CJ",
        "colab_type": "code",
        "outputId": "abafbab6-336c-4d2e-91de-5a0e1ce8a207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "# TODO: We use binary classification here - for multiple classes, convert classes to one-hot vectors.\n",
        "y = np.concatenate([bboxes / img_size, shapes], axis=-1).reshape(num_imgs, -1)\n",
        "\n",
        "print(y.shape)\n",
        "\n",
        "print(\"bboes\",bboxes[0])\n",
        "print(\"shape\",shapes[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10)\n",
            "bboes [[5. 5. 3. 4.]\n",
            " [1. 6. 4. 4.]]\n",
            "shape [[0.]\n",
            " [0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_9Eggjj3Rz_H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i = int(0.8 * num_imgs)\n",
        "train_X = X[:i]\n",
        "test_X = X[i:]\n",
        "train_y = y[:i]\n",
        "test_y = y[i:]\n",
        "test_imgs = imgs[i:]\n",
        "test_bboxes = bboxes[i:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5LFLGnjQRz8D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.optimizers import SGD\n",
        "model = Sequential([\n",
        "        Dense(256, input_dim=X.shape[-1]), \n",
        "        Activation('relu'), \n",
        "        Dropout(0.4), \n",
        "        Dense(y.shape[-1])\n",
        "    ])\n",
        "model.compile('adadelta', 'mse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TR2r49kdRz4d",
        "colab_type": "code",
        "outputId": "76cf961a-d664-4456-8cab-5307469ded56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12174
        }
      },
      "cell_type": "code",
      "source": [
        "# Flip bboxes during training.\n",
        "# Note: The validation loss is always quite big here because we don't flip the bounding boxes for the validation data. \n",
        "def IOU(bbox1, bbox2):\n",
        "    '''Calculate overlap between two bounding boxes [x, y, w, h] as the area of intersection over the area of unity'''\n",
        "    x1, y1, w1, h1 = bbox1[0], bbox1[1], bbox1[2], bbox1[3]  # TODO: Check if its more performant if tensor elements are accessed directly below.\n",
        "    x2, y2, w2, h2 = bbox2[0], bbox2[1], bbox2[2], bbox2[3]\n",
        "\n",
        "    w_I = min(x1 + w1, x2 + w2) - max(x1, x2)\n",
        "    h_I = min(y1 + h1, y2 + h2) - max(y1, y2)\n",
        "    w_I = max(w_I, 0)  # set w_I and h_I zero if there is no intersection\n",
        "    h_I = max(h_I, 0)\n",
        "    I = w_I * h_I\n",
        "\n",
        "    U = w1 * h1 + w2 * h2 - I\n",
        "\n",
        "    return I / U\n",
        "\n",
        "def dist(bbox1, bbox2):\n",
        "    return np.sqrt(np.sum(np.square(bbox1[:2] - bbox2[:2])))\n",
        "\n",
        "num_epochs = 100\n",
        "flipped_train_y = np.array(train_y)\n",
        "flipped = np.zeros((len(flipped_train_y), num_epochs))\n",
        "ious = np.zeros((len(flipped_train_y), num_epochs))\n",
        "dists = np.zeros((len(flipped_train_y), num_epochs))\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print ('Epoch', epoch)\n",
        "    model.fit(train_X, flipped_train_y, epochs=1, validation_data=(test_X, test_y), verbose=1)\n",
        "    pred_y = model.predict(train_X)\n",
        "\n",
        "    for i, (pred_bboxes, exp_bboxes) in enumerate(zip(pred_y, flipped_train_y)):\n",
        "        \n",
        "        flipped_exp_bboxes = np.concatenate([exp_bboxes[4:], exp_bboxes[:4]])\n",
        "        \n",
        "        mse = np.mean(np.square(pred_bboxes - exp_bboxes))\n",
        "        mse_flipped = np.mean(np.square(pred_bboxes - flipped_exp_bboxes))\n",
        "        \n",
        "        iou = IOU(pred_bboxes[:4], exp_bboxes[:4]) + IOU(pred_bboxes[4:], exp_bboxes[4:])\n",
        "        iou_flipped = IOU(pred_bboxes[:4], flipped_exp_bboxes[:4]) + IOU(pred_bboxes[4:], flipped_exp_bboxes[4:])\n",
        "        \n",
        "        dist = IOU(pred_bboxes[:4], exp_bboxes[:4]) + IOU(pred_bboxes[4:], exp_bboxes[4:])\n",
        "        dist_flipped = IOU(pred_bboxes[:4], flipped_exp_bboxes[:4]) + IOU(pred_bboxes[4:], flipped_exp_bboxes[4:])\n",
        "        \n",
        "        if mse_flipped < mse:  # using iou or dist here leads to similar results\n",
        "            flipped_train_y[i] = flipped_exp_bboxes\n",
        "            flipped[i,epoch] = 1\n",
        "            ious[i, epoch] = iou_flipped / 2\n",
        "            dists[i, epoch] = dist_flipped / 2\n",
        "            \n",
        "        else:\n",
        "            ious[i, epoch] = iou / 2\n",
        "            dists[i, epoch] = dist / 2\n",
        "            \n",
        "    print('Flipped {} training samples {}'.format(np.sum(flipped[:,epoch]), np.mean(flipped[:,epoch])))\n",
        "    print('Mean IOU: {}'.format(np.mean(ious[:,epoch])))\n",
        "    print('Mean dist: {}'.format(np.mean(dists[:,epoch])))\n",
        "   \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 160us/step - loss: 0.0404 - val_loss: 0.0420\n",
            "Flipped 1805.0 training samples 0.045125\n",
            "Mean IOU: 0.18045986823809157\n",
            "Mean dist: 0.18045986823809157\n",
            "Epoch 1\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0390 - val_loss: 0.0425\n",
            "Flipped 1499.0 training samples 0.037475\n",
            "Mean IOU: 0.1829125593153254\n",
            "Mean dist: 0.1829125593153254\n",
            "Epoch 2\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0384 - val_loss: 0.0428\n",
            "Flipped 1122.0 training samples 0.02805\n",
            "Mean IOU: 0.18009884237222362\n",
            "Mean dist: 0.18009884237222362\n",
            "Epoch 3\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 164us/step - loss: 0.0379 - val_loss: 0.0434\n",
            "Flipped 1801.0 training samples 0.045025\n",
            "Mean IOU: 0.17791228085799698\n",
            "Mean dist: 0.17791228085799698\n",
            "Epoch 4\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 164us/step - loss: 0.0372 - val_loss: 0.0445\n",
            "Flipped 1345.0 training samples 0.033625\n",
            "Mean IOU: 0.17976273166579848\n",
            "Mean dist: 0.17976273166579848\n",
            "Epoch 5\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0365 - val_loss: 0.0459\n",
            "Flipped 1257.0 training samples 0.031425\n",
            "Mean IOU: 0.1766170654630112\n",
            "Mean dist: 0.1766170654630112\n",
            "Epoch 6\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0360 - val_loss: 0.0467\n",
            "Flipped 1086.0 training samples 0.02715\n",
            "Mean IOU: 0.17158169958735955\n",
            "Mean dist: 0.17158169958735955\n",
            "Epoch 7\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 163us/step - loss: 0.0354 - val_loss: 0.0480\n",
            "Flipped 776.0 training samples 0.0194\n",
            "Mean IOU: 0.17004390576483688\n",
            "Mean dist: 0.17004390576483688\n",
            "Epoch 8\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0351 - val_loss: 0.0495\n",
            "Flipped 760.0 training samples 0.019\n",
            "Mean IOU: 0.15796006695253226\n",
            "Mean dist: 0.15796006695253226\n",
            "Epoch 9\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 163us/step - loss: 0.0348 - val_loss: 0.0498\n",
            "Flipped 609.0 training samples 0.015225\n",
            "Mean IOU: 0.16225495984061516\n",
            "Mean dist: 0.16225495984061516\n",
            "Epoch 10\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0345 - val_loss: 0.0501\n",
            "Flipped 328.0 training samples 0.0082\n",
            "Mean IOU: 0.1651476267385958\n",
            "Mean dist: 0.1651476267385958\n",
            "Epoch 11\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0344 - val_loss: 0.0502\n",
            "Flipped 378.0 training samples 0.00945\n",
            "Mean IOU: 0.1574832940450331\n",
            "Mean dist: 0.1574832940450331\n",
            "Epoch 12\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0343 - val_loss: 0.0516\n",
            "Flipped 270.0 training samples 0.00675\n",
            "Mean IOU: 0.15623353032074905\n",
            "Mean dist: 0.15623353032074905\n",
            "Epoch 13\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0343 - val_loss: 0.0502\n",
            "Flipped 167.0 training samples 0.004175\n",
            "Mean IOU: 0.1633711287925414\n",
            "Mean dist: 0.1633711287925414\n",
            "Epoch 14\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0341 - val_loss: 0.0519\n",
            "Flipped 260.0 training samples 0.0065\n",
            "Mean IOU: 0.15516932432231306\n",
            "Mean dist: 0.15516932432231306\n",
            "Epoch 15\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 160us/step - loss: 0.0340 - val_loss: 0.0514\n",
            "Flipped 239.0 training samples 0.005975\n",
            "Mean IOU: 0.16145067413068287\n",
            "Mean dist: 0.16145067413068287\n",
            "Epoch 16\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0340 - val_loss: 0.0515\n",
            "Flipped 219.0 training samples 0.005475\n",
            "Mean IOU: 0.15365332598930792\n",
            "Mean dist: 0.15365332598930792\n",
            "Epoch 17\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 160us/step - loss: 0.0339 - val_loss: 0.0506\n",
            "Flipped 123.0 training samples 0.003075\n",
            "Mean IOU: 0.16257141746185824\n",
            "Mean dist: 0.16257141746185824\n",
            "Epoch 18\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0340 - val_loss: 0.0522\n",
            "Flipped 151.0 training samples 0.003775\n",
            "Mean IOU: 0.15449478581991408\n",
            "Mean dist: 0.15449478581991408\n",
            "Epoch 19\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0338 - val_loss: 0.0509\n",
            "Flipped 97.0 training samples 0.002425\n",
            "Mean IOU: 0.1572480936943644\n",
            "Mean dist: 0.1572480936943644\n",
            "Epoch 20\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0338 - val_loss: 0.0522\n",
            "Flipped 91.0 training samples 0.002275\n",
            "Mean IOU: 0.15803518428662688\n",
            "Mean dist: 0.15803518428662688\n",
            "Epoch 21\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0337 - val_loss: 0.0516\n",
            "Flipped 97.0 training samples 0.002425\n",
            "Mean IOU: 0.15805421173221215\n",
            "Mean dist: 0.15805421173221215\n",
            "Epoch 22\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0337 - val_loss: 0.0509\n",
            "Flipped 88.0 training samples 0.0022\n",
            "Mean IOU: 0.16312866516101876\n",
            "Mean dist: 0.16312866516101876\n",
            "Epoch 23\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 159us/step - loss: 0.0336 - val_loss: 0.0513\n",
            "Flipped 89.0 training samples 0.002225\n",
            "Mean IOU: 0.1596930743024939\n",
            "Mean dist: 0.1596930743024939\n",
            "Epoch 24\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 160us/step - loss: 0.0336 - val_loss: 0.0529\n",
            "Flipped 84.0 training samples 0.0021\n",
            "Mean IOU: 0.1547696981425944\n",
            "Mean dist: 0.1547696981425944\n",
            "Epoch 25\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 163us/step - loss: 0.0336 - val_loss: 0.0513\n",
            "Flipped 70.0 training samples 0.00175\n",
            "Mean IOU: 0.16011233514660636\n",
            "Mean dist: 0.16011233514660636\n",
            "Epoch 26\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 164us/step - loss: 0.0336 - val_loss: 0.0524\n",
            "Flipped 150.0 training samples 0.00375\n",
            "Mean IOU: 0.15445705832505757\n",
            "Mean dist: 0.15445705832505757\n",
            "Epoch 27\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 164us/step - loss: 0.0336 - val_loss: 0.0527\n",
            "Flipped 83.0 training samples 0.002075\n",
            "Mean IOU: 0.1575181039071405\n",
            "Mean dist: 0.1575181039071405\n",
            "Epoch 28\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 163us/step - loss: 0.0335 - val_loss: 0.0519\n",
            "Flipped 76.0 training samples 0.0019\n",
            "Mean IOU: 0.15882694623400911\n",
            "Mean dist: 0.15882694623400911\n",
            "Epoch 29\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 160us/step - loss: 0.0335 - val_loss: 0.0523\n",
            "Flipped 34.0 training samples 0.00085\n",
            "Mean IOU: 0.15268072299429142\n",
            "Mean dist: 0.15268072299429142\n",
            "Epoch 30\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 163us/step - loss: 0.0335 - val_loss: 0.0531\n",
            "Flipped 79.0 training samples 0.001975\n",
            "Mean IOU: 0.15332485632112786\n",
            "Mean dist: 0.15332485632112786\n",
            "Epoch 31\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 163us/step - loss: 0.0334 - val_loss: 0.0517\n",
            "Flipped 71.0 training samples 0.001775\n",
            "Mean IOU: 0.15981702400138015\n",
            "Mean dist: 0.15981702400138015\n",
            "Epoch 32\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 163us/step - loss: 0.0334 - val_loss: 0.0523\n",
            "Flipped 64.0 training samples 0.0016\n",
            "Mean IOU: 0.15677929547522176\n",
            "Mean dist: 0.15677929547522176\n",
            "Epoch 33\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0335 - val_loss: 0.0522\n",
            "Flipped 47.0 training samples 0.001175\n",
            "Mean IOU: 0.15895835600784497\n",
            "Mean dist: 0.15895835600784497\n",
            "Epoch 34\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0334 - val_loss: 0.0522\n",
            "Flipped 39.0 training samples 0.000975\n",
            "Mean IOU: 0.1605729966724696\n",
            "Mean dist: 0.1605729966724696\n",
            "Epoch 35\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0333 - val_loss: 0.0527\n",
            "Flipped 58.0 training samples 0.00145\n",
            "Mean IOU: 0.15877151359079938\n",
            "Mean dist: 0.15877151359079938\n",
            "Epoch 36\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 163us/step - loss: 0.0334 - val_loss: 0.0527\n",
            "Flipped 45.0 training samples 0.001125\n",
            "Mean IOU: 0.15518232603701043\n",
            "Mean dist: 0.15518232603701043\n",
            "Epoch 37\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 163us/step - loss: 0.0333 - val_loss: 0.0530\n",
            "Flipped 62.0 training samples 0.00155\n",
            "Mean IOU: 0.15914091380492418\n",
            "Mean dist: 0.15914091380492418\n",
            "Epoch 38\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0333 - val_loss: 0.0531\n",
            "Flipped 56.0 training samples 0.0014\n",
            "Mean IOU: 0.15551084415611624\n",
            "Mean dist: 0.15551084415611624\n",
            "Epoch 39\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0333 - val_loss: 0.0523\n",
            "Flipped 67.0 training samples 0.001675\n",
            "Mean IOU: 0.16095275148293303\n",
            "Mean dist: 0.16095275148293303\n",
            "Epoch 40\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0332 - val_loss: 0.0526\n",
            "Flipped 32.0 training samples 0.0008\n",
            "Mean IOU: 0.1597379521287908\n",
            "Mean dist: 0.1597379521287908\n",
            "Epoch 41\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0332 - val_loss: 0.0530\n",
            "Flipped 52.0 training samples 0.0013\n",
            "Mean IOU: 0.1534035769154275\n",
            "Mean dist: 0.1534035769154275\n",
            "Epoch 42\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 160us/step - loss: 0.0331 - val_loss: 0.0531\n",
            "Flipped 31.0 training samples 0.000775\n",
            "Mean IOU: 0.15499789936418246\n",
            "Mean dist: 0.15499789936418246\n",
            "Epoch 43\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0331 - val_loss: 0.0523\n",
            "Flipped 28.0 training samples 0.0007\n",
            "Mean IOU: 0.15856096940506087\n",
            "Mean dist: 0.15856096940506087\n",
            "Epoch 44\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 160us/step - loss: 0.0331 - val_loss: 0.0524\n",
            "Flipped 20.0 training samples 0.0005\n",
            "Mean IOU: 0.15873932566564736\n",
            "Mean dist: 0.15873932566564736\n",
            "Epoch 45\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0331 - val_loss: 0.0529\n",
            "Flipped 30.0 training samples 0.00075\n",
            "Mean IOU: 0.16606216561428636\n",
            "Mean dist: 0.16606216561428636\n",
            "Epoch 46\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 163us/step - loss: 0.0332 - val_loss: 0.0524\n",
            "Flipped 33.0 training samples 0.000825\n",
            "Mean IOU: 0.16306086546278833\n",
            "Mean dist: 0.16306086546278833\n",
            "Epoch 47\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0331 - val_loss: 0.0523\n",
            "Flipped 35.0 training samples 0.000875\n",
            "Mean IOU: 0.15872724753157252\n",
            "Mean dist: 0.15872724753157252\n",
            "Epoch 48\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0329 - val_loss: 0.0525\n",
            "Flipped 23.0 training samples 0.000575\n",
            "Mean IOU: 0.16069002182923786\n",
            "Mean dist: 0.16069002182923786\n",
            "Epoch 49\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0330 - val_loss: 0.0519\n",
            "Flipped 44.0 training samples 0.0011\n",
            "Mean IOU: 0.17040459041410588\n",
            "Mean dist: 0.17040459041410588\n",
            "Epoch 50\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0329 - val_loss: 0.0524\n",
            "Flipped 34.0 training samples 0.00085\n",
            "Mean IOU: 0.1597388306265636\n",
            "Mean dist: 0.1597388306265636\n",
            "Epoch 51\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 164us/step - loss: 0.0329 - val_loss: 0.0527\n",
            "Flipped 23.0 training samples 0.000575\n",
            "Mean IOU: 0.16125915634209448\n",
            "Mean dist: 0.16125915634209448\n",
            "Epoch 52\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 159us/step - loss: 0.0330 - val_loss: 0.0531\n",
            "Flipped 25.0 training samples 0.000625\n",
            "Mean IOU: 0.16306387543893391\n",
            "Mean dist: 0.16306387543893391\n",
            "Epoch 53\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 160us/step - loss: 0.0330 - val_loss: 0.0526\n",
            "Flipped 35.0 training samples 0.000875\n",
            "Mean IOU: 0.16318726565426053\n",
            "Mean dist: 0.16318726565426053\n",
            "Epoch 54\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0329 - val_loss: 0.0529\n",
            "Flipped 22.0 training samples 0.00055\n",
            "Mean IOU: 0.1642131485257701\n",
            "Mean dist: 0.1642131485257701\n",
            "Epoch 55\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0328 - val_loss: 0.0521\n",
            "Flipped 23.0 training samples 0.000575\n",
            "Mean IOU: 0.16635795242686263\n",
            "Mean dist: 0.16635795242686263\n",
            "Epoch 56\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0329 - val_loss: 0.0526\n",
            "Flipped 21.0 training samples 0.000525\n",
            "Mean IOU: 0.1614248975611969\n",
            "Mean dist: 0.1614248975611969\n",
            "Epoch 57\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0328 - val_loss: 0.0526\n",
            "Flipped 20.0 training samples 0.0005\n",
            "Mean IOU: 0.1658443881943948\n",
            "Mean dist: 0.1658443881943948\n",
            "Epoch 58\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 160us/step - loss: 0.0328 - val_loss: 0.0530\n",
            "Flipped 25.0 training samples 0.000625\n",
            "Mean IOU: 0.16143539089795253\n",
            "Mean dist: 0.16143539089795253\n",
            "Epoch 59\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0328 - val_loss: 0.0534\n",
            "Flipped 23.0 training samples 0.000575\n",
            "Mean IOU: 0.16036804075096925\n",
            "Mean dist: 0.16036804075096925\n",
            "Epoch 60\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0327 - val_loss: 0.0534\n",
            "Flipped 19.0 training samples 0.000475\n",
            "Mean IOU: 0.1622634409934085\n",
            "Mean dist: 0.1622634409934085\n",
            "Epoch 61\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0328 - val_loss: 0.0531\n",
            "Flipped 25.0 training samples 0.000625\n",
            "Mean IOU: 0.16392727782422659\n",
            "Mean dist: 0.16392727782422659\n",
            "Epoch 62\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0328 - val_loss: 0.0528\n",
            "Flipped 32.0 training samples 0.0008\n",
            "Mean IOU: 0.16256047512843788\n",
            "Mean dist: 0.16256047512843788\n",
            "Epoch 63\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0329 - val_loss: 0.0529\n",
            "Flipped 17.0 training samples 0.000425\n",
            "Mean IOU: 0.1647799326344243\n",
            "Mean dist: 0.1647799326344243\n",
            "Epoch 64\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0327 - val_loss: 0.0527\n",
            "Flipped 26.0 training samples 0.00065\n",
            "Mean IOU: 0.16353491403158332\n",
            "Mean dist: 0.16353491403158332\n",
            "Epoch 65\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0328 - val_loss: 0.0526\n",
            "Flipped 20.0 training samples 0.0005\n",
            "Mean IOU: 0.16175631421265743\n",
            "Mean dist: 0.16175631421265743\n",
            "Epoch 66\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0327 - val_loss: 0.0526\n",
            "Flipped 31.0 training samples 0.000775\n",
            "Mean IOU: 0.16364376395542846\n",
            "Mean dist: 0.16364376395542846\n",
            "Epoch 67\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0327 - val_loss: 0.0533\n",
            "Flipped 25.0 training samples 0.000625\n",
            "Mean IOU: 0.16137678907637215\n",
            "Mean dist: 0.16137678907637215\n",
            "Epoch 68\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0327 - val_loss: 0.0526\n",
            "Flipped 24.0 training samples 0.0006\n",
            "Mean IOU: 0.1650346368396068\n",
            "Mean dist: 0.1650346368396068\n",
            "Epoch 69\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0327 - val_loss: 0.0523\n",
            "Flipped 17.0 training samples 0.000425\n",
            "Mean IOU: 0.1648847531557086\n",
            "Mean dist: 0.1648847531557086\n",
            "Epoch 70\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0326 - val_loss: 0.0543\n",
            "Flipped 26.0 training samples 0.00065\n",
            "Mean IOU: 0.15663133199263576\n",
            "Mean dist: 0.15663133199263576\n",
            "Epoch 71\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0325 - val_loss: 0.0533\n",
            "Flipped 15.0 training samples 0.000375\n",
            "Mean IOU: 0.1647371642925778\n",
            "Mean dist: 0.1647371642925778\n",
            "Epoch 72\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 163us/step - loss: 0.0326 - val_loss: 0.0540\n",
            "Flipped 29.0 training samples 0.000725\n",
            "Mean IOU: 0.16174633329972432\n",
            "Mean dist: 0.16174633329972432\n",
            "Epoch 73\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 163us/step - loss: 0.0325 - val_loss: 0.0533\n",
            "Flipped 26.0 training samples 0.00065\n",
            "Mean IOU: 0.1634182155243729\n",
            "Mean dist: 0.1634182155243729\n",
            "Epoch 74\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 163us/step - loss: 0.0326 - val_loss: 0.0531\n",
            "Flipped 25.0 training samples 0.000625\n",
            "Mean IOU: 0.1656211604542933\n",
            "Mean dist: 0.1656211604542933\n",
            "Epoch 75\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 164us/step - loss: 0.0327 - val_loss: 0.0527\n",
            "Flipped 22.0 training samples 0.00055\n",
            "Mean IOU: 0.16605625220747966\n",
            "Mean dist: 0.16605625220747966\n",
            "Epoch 76\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 163us/step - loss: 0.0326 - val_loss: 0.0528\n",
            "Flipped 23.0 training samples 0.000575\n",
            "Mean IOU: 0.1690041232354777\n",
            "Mean dist: 0.1690041232354777\n",
            "Epoch 77\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0325 - val_loss: 0.0535\n",
            "Flipped 25.0 training samples 0.000625\n",
            "Mean IOU: 0.16132181366238588\n",
            "Mean dist: 0.16132181366238588\n",
            "Epoch 78\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0327 - val_loss: 0.0528\n",
            "Flipped 22.0 training samples 0.00055\n",
            "Mean IOU: 0.16121429455395572\n",
            "Mean dist: 0.16121429455395572\n",
            "Epoch 79\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0324 - val_loss: 0.0531\n",
            "Flipped 12.0 training samples 0.0003\n",
            "Mean IOU: 0.16324125778911056\n",
            "Mean dist: 0.16324125778911056\n",
            "Epoch 80\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 163us/step - loss: 0.0324 - val_loss: 0.0536\n",
            "Flipped 18.0 training samples 0.00045\n",
            "Mean IOU: 0.16031617989221272\n",
            "Mean dist: 0.16031617989221272\n",
            "Epoch 81\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 163us/step - loss: 0.0324 - val_loss: 0.0536\n",
            "Flipped 25.0 training samples 0.000625\n",
            "Mean IOU: 0.16311242209415677\n",
            "Mean dist: 0.16311242209415677\n",
            "Epoch 82\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 163us/step - loss: 0.0326 - val_loss: 0.0537\n",
            "Flipped 13.0 training samples 0.000325\n",
            "Mean IOU: 0.16782096197611027\n",
            "Mean dist: 0.16782096197611027\n",
            "Epoch 83\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0325 - val_loss: 0.0540\n",
            "Flipped 22.0 training samples 0.00055\n",
            "Mean IOU: 0.16155301780092987\n",
            "Mean dist: 0.16155301780092987\n",
            "Epoch 84\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 160us/step - loss: 0.0325 - val_loss: 0.0535\n",
            "Flipped 15.0 training samples 0.000375\n",
            "Mean IOU: 0.16322156772114063\n",
            "Mean dist: 0.16322156772114063\n",
            "Epoch 85\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0324 - val_loss: 0.0534\n",
            "Flipped 26.0 training samples 0.00065\n",
            "Mean IOU: 0.16326766592412756\n",
            "Mean dist: 0.16326766592412756\n",
            "Epoch 86\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0325 - val_loss: 0.0537\n",
            "Flipped 18.0 training samples 0.00045\n",
            "Mean IOU: 0.16248892357967076\n",
            "Mean dist: 0.16248892357967076\n",
            "Epoch 87\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0323 - val_loss: 0.0539\n",
            "Flipped 19.0 training samples 0.000475\n",
            "Mean IOU: 0.16199732615349605\n",
            "Mean dist: 0.16199732615349605\n",
            "Epoch 88\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0325 - val_loss: 0.0535\n",
            "Flipped 19.0 training samples 0.000475\n",
            "Mean IOU: 0.16809243222794115\n",
            "Mean dist: 0.16809243222794115\n",
            "Epoch 89\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0324 - val_loss: 0.0543\n",
            "Flipped 30.0 training samples 0.00075\n",
            "Mean IOU: 0.15767424224873447\n",
            "Mean dist: 0.15767424224873447\n",
            "Epoch 90\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0323 - val_loss: 0.0533\n",
            "Flipped 24.0 training samples 0.0006\n",
            "Mean IOU: 0.1626625104023502\n",
            "Mean dist: 0.1626625104023502\n",
            "Epoch 91\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0323 - val_loss: 0.0526\n",
            "Flipped 29.0 training samples 0.000725\n",
            "Mean IOU: 0.16658457625345544\n",
            "Mean dist: 0.16658457625345544\n",
            "Epoch 92\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0324 - val_loss: 0.0539\n",
            "Flipped 19.0 training samples 0.000475\n",
            "Mean IOU: 0.16288038277540107\n",
            "Mean dist: 0.16288038277540107\n",
            "Epoch 93\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 163us/step - loss: 0.0324 - val_loss: 0.0533\n",
            "Flipped 15.0 training samples 0.000375\n",
            "Mean IOU: 0.16739937717075518\n",
            "Mean dist: 0.16739937717075518\n",
            "Epoch 94\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0323 - val_loss: 0.0530\n",
            "Flipped 18.0 training samples 0.00045\n",
            "Mean IOU: 0.16399413199342402\n",
            "Mean dist: 0.16399413199342402\n",
            "Epoch 95\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 160us/step - loss: 0.0323 - val_loss: 0.0535\n",
            "Flipped 13.0 training samples 0.000325\n",
            "Mean IOU: 0.16369932809655308\n",
            "Mean dist: 0.16369932809655308\n",
            "Epoch 96\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 162us/step - loss: 0.0323 - val_loss: 0.0527\n",
            "Flipped 29.0 training samples 0.000725\n",
            "Mean IOU: 0.1687058479228267\n",
            "Mean dist: 0.1687058479228267\n",
            "Epoch 97\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 160us/step - loss: 0.0322 - val_loss: 0.0535\n",
            "Flipped 18.0 training samples 0.00045\n",
            "Mean IOU: 0.16554288621767643\n",
            "Mean dist: 0.16554288621767643\n",
            "Epoch 98\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 161us/step - loss: 0.0323 - val_loss: 0.0534\n",
            "Flipped 19.0 training samples 0.000475\n",
            "Mean IOU: 0.1609502053602009\n",
            "Mean dist: 0.1609502053602009\n",
            "Epoch 99\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 7s 163us/step - loss: 0.0323 - val_loss: 0.0536\n",
            "Flipped 10.0 training samples 0.00025\n",
            "Mean IOU: 0.16112122527319783\n",
            "Mean dist: 0.16112122527319783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iiAMUK6RRz0h",
        "colab_type": "code",
        "outputId": "0f91ae5a-ca34-4d6b-9b55-a278db1bd69e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "cell_type": "code",
      "source": [
        "plt.pcolor(flipped[:1000], cmap='Greys')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training sample')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0,0.5,'Training sample')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbfbe2ee8d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "gwV5jhASRzwQ",
        "colab_type": "code",
        "outputId": "ccbca4da-fd14-42bd-ae91-714dc2eb4f16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "plt.plot(np.mean(ious, axis=0), label='Mean IOU')  # between predicted and assigned true bboxes\n",
        "#plt.plot(np.mean(dists, axis=0), label='Mean distance')  # relative to image size\n",
        "plt.legend()\n",
        "plt.ylim(0, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD8CAYAAABq6S8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbf95f51fd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "brcT1ootRzs6",
        "colab_type": "code",
        "outputId": "1687d895-1bc9-4bb2-9b6f-91921cda836b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "pred_y = model.predict(test_X)\n",
        "pred_y = pred_y.reshape(len(pred_y), num_objects, -1)\n",
        "pred_bboxes = pred_y[..., :4] * img_size\n",
        "pred_shapes = pred_y[..., 4:5]\n",
        "pred_bboxes.shape, pred_shapes.shape\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7.152958   4.8067274  4.9991307  4.287347   0.03963017]\n",
            " [4.1923513  5.3603163  4.506345   4.102917   4.3760343 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c_2aBeiNRzpY",
        "colab_type": "code",
        "outputId": "ed016de8-154c-4870-b5f6-5fea0f6c18e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16, 8))\n",
        "for i_subplot in range(1, 5):\n",
        "    plt.subplot(1, 4, i_subplot)\n",
        "    i = np.random.randint(len(test_X))\n",
        "    plt.imshow(test_imgs[i].T, cmap='Greys', interpolation='none', origin='lower', extent=[0, img_size, 0, img_size])\n",
        "    for pred_bbox, exp_bbox, pred_shape in zip(pred_bboxes[i], test_bboxes[i], pred_shapes[i]):\n",
        "        plt.gca().add_patch(matplotlib.patches.Rectangle((pred_bbox[0], pred_bbox[1]), pred_bbox[2], pred_bbox[3], ec='r' if pred_shape[0] <= 0.5 else 'y', fc='none'))\n",
        "        # TODO: Calculate max IOU with all expected bounding boxes.\n",
        "#         plt.annotate('IOU: {:.2f}'.format(IOU(pred_bbox, exp_bbox)), (pred_bbox[0], pred_bbox[1]+pred_bbox[3]+0.4), color='r')\n",
        "\n",
        "# plt.savefig('plots/bw-two-rectangles-or-triangles4.png', dpi=300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA50AAADlCAYAAADQtZN7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAB0o+kEAACgm/8PUVuedWB6k80AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbf95df8390>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "XnuZpTnYRzmV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mxYtc4xmRzjU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WoCa4qMPRzf_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ih372nAsRzcO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yqUpTJZhRzZB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m_q4i3N1RzVc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I_oIUM9xRzRx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FwIa5XhDRzNb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}